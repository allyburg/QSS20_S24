{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 2: Merging and regular expressions\n",
    "\n",
    "**Total points (without extra credit)**: 30 \n",
    "\n",
    "**Background on the policy context**: here, we're going to use two datasets to practice reshaping, merging, and regular expression patterns. Both datasets relate to the broader issue of which employers might be violating the rights of temporary guestworkers granted visas under the H-2A program. Here are some articles about potential exploitation of guestworkers by firms and inequality caused by minimal oversight:\n",
    "\n",
    "- News media coverage of labor abuses of temporary guestworkers: https://www.buzzfeednews.com/article/kenbensinger/the-pushovers \n",
    "- GAO report on labor abuses of temporary guestworkers: https://www.gao.gov/products/gao-15-154\n",
    "\n",
    "The following datasets are located in `pset2_inputdata` (need to unzip): \n",
    "\n",
    "- `jobs_clean`: a dataset of guestworker jobs posted by many employers, some of whom have been debarred (banned) from the program for labor abuses; others not debarred\n",
    "- `debar`: a dataset of employers who committed violations of labor regulations meant to protect temporary guestworkers \n",
    "\n",
    "\n",
    "You can view a codebook here: https://docs.google.com/spreadsheets/d/1rF9GJEC8pPKxipD0TsoG9DVdqz3EJ-b-BHEtyioAX7I/edit?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helpful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reshaping data (13 points total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the following dataset stored in `pset2_inputdata`: `debar.csv`\n",
    "\n",
    "This represents employers temporarily banned from hiring workers (debar.csv); call this `debar`\n",
    "\n",
    "\n",
    "View the head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Name     City, State  \\\n",
      "0                    J&J Harvesting       Leads, ND   \n",
      "1            Stahlman Apiaries, Inc       Selby, SD   \n",
      "2                     Trust Nursery     Pulaski, NY   \n",
      "3             Anton Fertilizer Inc.     Dighton, KS   \n",
      "4  Great Plains Fluid Service, Inc.  Greensburg, KS   \n",
      "\n",
      "                                        Violation Duration Start date  \\\n",
      "0  Failure to respond to audit (partial response)  2 years  1/19/2014   \n",
      "1  Failure to respond to audit (partial response)   1 year  2/19/2015   \n",
      "2  Failure to respond to audit (partial response)   1 year  3/21/2014   \n",
      "3       Failure to respond to audit (no response)  2 years  3/30/2014   \n",
      "4       Failure to respond to audit (no response)  2 years  3/30/2014   \n",
      "\n",
      "    End date  \n",
      "0  1/18/2016  \n",
      "1  2/14/2016  \n",
      "2  3/20/2015  \n",
      "3  3/29/2016  \n",
      "4  3/29/2016  \n",
      "(114, 6)\n"
     ]
    }
   ],
   "source": [
    "## your code here\n",
    "debar = pd.read_csv(r\"/Users/fintanletzelter/Documents/GitHub/QSS20_S24/problemsets/pset2/pset2_inputdata/debar.csv\")\n",
    "print(debar.head())\n",
    "print(debar.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 (1 point)\n",
    "\n",
    "Print the number of rows in `debar` versus the number of unique employer names (`Name`). Is there one row per employer or multiple rows for some employers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "98\n",
      "There are multiple rows for some employers\n"
     ]
    }
   ],
   "source": [
    "## your code here\n",
    "print(debar.shape[0])\n",
    "print(len(set(debar.Name)))\n",
    "\n",
    "print(\"There are multiple rows for some employers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Investigating duplicated rows (2 points)\n",
    "\n",
    "A. Create a new column in `debar`--`is_repeated`-- that tells us whether an employer (`Name`) is repeated > 1 times\n",
    "\n",
    "*Hint*: there are multiple ways to solve this but some possibilities to get the list of names that are repeated are:\n",
    "- Using value_counts() on the `Name` variable and extracting the index from that value counts \n",
    "- Using groupby to count the rows attached to one name\n",
    "\n",
    "B. Print the rows where `is_repeated == True` and interpret\n",
    "\n",
    "C. Subset to the rows where `is_repeated == True` and save that data as `mult_debar`. Print the head() and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Name       City, State  \\\n",
      "6                    Annabella Land & Cattle     Annabella, UT   \n",
      "7                        Autumn Hill Orchard        Groton, MA   \n",
      "8      Caddo Creek Ranch, dba Paradise Ranch         Caddo, TX   \n",
      "11                     Loewen Harvesting LLC   Brownsville, TX   \n",
      "12               Rollo Farm Labor Contractor         Miami, FL   \n",
      "14                             Sharon Mathis        Tifton, GA   \n",
      "15                                 SRT Farms        Morton, TX   \n",
      "16                               Mark Duncan     Roosevelt, UT   \n",
      "17          Maple Ridge Custom Services, LLC     Altheimer, AK   \n",
      "18                                 F&W Farms       Ingalls, KS   \n",
      "19                        Cisco Produce Inc.         Cairo, GA   \n",
      "21   Old Tree Farms/Verpaalen Custom Service         Volga, SD   \n",
      "24               Rollo Farm Labor Contractor         Miami, FL   \n",
      "25                     Loewen Harvesting LLC    Brownfield, TX   \n",
      "28     Caddo Creek Ranch, dba Paradise Ranch      Caddo, Texas   \n",
      "29                       Autumn Hill Orchard        Groton, MA   \n",
      "30                   Annabella Land & Cattle   Annabella, Utah   \n",
      "31                      Macky and Brad Farms        Plains, TX   \n",
      "51   Old Tree Farms/Verpaalen Custom Service         Volga, SD   \n",
      "55                      Macky and Brad Farms        Plains, TX   \n",
      "56                        Cisco Produce Inc.         Cairo, GA   \n",
      "58                                 F&W Farms       Ingalls, KS   \n",
      "59          Maple Ridge Custom Services, LLC     Altheimer, AR   \n",
      "60                               Mark Duncan     Roosevelt, UT   \n",
      "61                                 SRT Farms        Morton, TX   \n",
      "62                             Sharon Mathis        Tifton, GA   \n",
      "73                              Xavier Horne    Lyons, Georgia   \n",
      "89                              Xavier Horne    Lyons, Georgia   \n",
      "103                         Dove Creek Farms  Mount Vernon, TX   \n",
      "106                             Turner Farms         Healy, KS   \n",
      "109                         Dove Creek Farms  Mount Vernon, TX   \n",
      "111                             Turner Farms         Healy, KS   \n",
      "\n",
      "                                             Violation  Duration  Start date  \\\n",
      "6                                          Non Payment    1 year    5/9/2014   \n",
      "7            Failure to respond to audit (no response)   2 years    7/6/2014   \n",
      "8       Failure to respond to audit (partial response)   2 years   7/20/2014   \n",
      "11      Failure to respond to audit (partial response)    1 year   8/20/2014   \n",
      "12           Failure to respond to audit (no response)   2 years   8/23/2014   \n",
      "14           Failure to respond to audit (no response)   2 years  11/16/2014   \n",
      "15           Failure to respond to audit (no response)   2 years  11/16/2014   \n",
      "16           Failure to respond to audit (no response)   2 years  11/16/2014   \n",
      "17      Failure to respond to audit (partial response)   2 years  11/16/2014   \n",
      "18      Failure to respond to audit (partial response)   2 years  12/10/2014   \n",
      "19           Failure to respond to audit (no response)   2 years  12/10/2014   \n",
      "21                                       WHD Debarment   3 years  12/11/2014   \n",
      "24          Impeding the Audit Process – Non- Response   2 years   8/23/2014   \n",
      "25      Impeding the Audit Process – Partial- Response    1 year   8/20/2014   \n",
      "28      Impeding the Audit Process – Partial- Response   2 years   7/20/2014   \n",
      "29          Impeding the Audit Process – Non- Response   2 years    7/6/2014   \n",
      "30                                         Non-payment    1 year    5/9/2014   \n",
      "31           Failure to respond to audit (no response)    1 year   2/13/2015   \n",
      "51                                 Wage Hour Debarment   3 years   12/1/2014   \n",
      "55      Impeding the Audit Process – Partial- Response    1 year   2/13/2015   \n",
      "56          Impeding the Audit Process – Non- Response   2 years  12/10/2015   \n",
      "58      Impeding the Audit Process – Partial- Response    1 year  12/10/2014   \n",
      "59      Impeding the Audit Process – Partial- Response    1 year  11/16/2014   \n",
      "60          Impeding the Audit Process – Non- Response   2 years  11/16/2014   \n",
      "61          Impeding the Audit Process – Non- Response   2 years  11/16/2014   \n",
      "62          Impeding the Audit Process – Non- Response   2 years  11/16/2014   \n",
      "73                    Non-payment of certification fee    1 year   6/16/2016   \n",
      "89                 Failure to respond to audit request   2 years   9/27/2017   \n",
      "103                Failure to respond to audit request   2 years    2/9/2018   \n",
      "106  Failure to comply with the employer's obligati...  6 months     7/17/19   \n",
      "109                Failure to Respond to Audit Request   2 years    2/9/2018   \n",
      "111  Failure to comply with the employer's obligati...  7 months     7/17/19   \n",
      "\n",
      "       End date  is_repeated  \n",
      "6      5/9/2015         True  \n",
      "7      7/5/2016         True  \n",
      "8     7/19/2016         True  \n",
      "11    8/19/2015         True  \n",
      "12    8/22/2016         True  \n",
      "14   11/15/2016         True  \n",
      "15   11/15/2016         True  \n",
      "16   11/15/2016         True  \n",
      "17   11/15/2016         True  \n",
      "18    12/9/2016         True  \n",
      "19    12/9/2016         True  \n",
      "21   12/10/2017         True  \n",
      "24    8/22/2016         True  \n",
      "25    8/19/2015         True  \n",
      "28    7/19/2016         True  \n",
      "29     7/5/2016         True  \n",
      "30     5/8/2015         True  \n",
      "31    2/12/2016         True  \n",
      "51    12/1/2017         True  \n",
      "55    2/12/2016         True  \n",
      "56    12/9/2017         True  \n",
      "58    12/9/2015         True  \n",
      "59   11/15/2015         True  \n",
      "60   11/15/2016         True  \n",
      "61   11/15/2016         True  \n",
      "62   11/15/2016         True  \n",
      "73    6/15/2017         True  \n",
      "89    9/26/2019         True  \n",
      "103    2/8/2018         True  \n",
      "106   2/10/2020         True  \n",
      "109    2/8/2020         True  \n",
      "111     2/10/20         True  \n",
      "(32, 7)\n",
      "                                     Name      City, State  \\\n",
      "6                 Annabella Land & Cattle    Annabella, UT   \n",
      "7                     Autumn Hill Orchard       Groton, MA   \n",
      "8   Caddo Creek Ranch, dba Paradise Ranch        Caddo, TX   \n",
      "11                  Loewen Harvesting LLC  Brownsville, TX   \n",
      "12            Rollo Farm Labor Contractor        Miami, FL   \n",
      "\n",
      "                                         Violation Duration Start date  \\\n",
      "6                                      Non Payment   1 year   5/9/2014   \n",
      "7        Failure to respond to audit (no response)  2 years   7/6/2014   \n",
      "8   Failure to respond to audit (partial response)  2 years  7/20/2014   \n",
      "11  Failure to respond to audit (partial response)   1 year  8/20/2014   \n",
      "12       Failure to respond to audit (no response)  2 years  8/23/2014   \n",
      "\n",
      "     End date  is_repeated  \n",
      "6    5/9/2015         True  \n",
      "7    7/5/2016         True  \n",
      "8   7/19/2016         True  \n",
      "11  8/19/2015         True  \n",
      "12  8/22/2016         True  \n"
     ]
    }
   ],
   "source": [
    "## your code here\n",
    "debar[\"is_repeated\"] = debar[\"Name\"].map(debar[\"Name\"].value_counts()) > 1\n",
    "print(debar[debar[\"is_repeated\"] == True])\n",
    "\n",
    "mult_debar = debar[debar[\"is_repeated\"] == True]\n",
    "print(mult_debar.shape)\n",
    "print(mult_debar.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Reshape mult_debar to wide to begin filtering out duplicates (4 points)\n",
    "\n",
    "You want to separate out two cases:\n",
    "\n",
    "- Cases where the repeat rows for one employer are due to duplicated data \n",
    "- Cases where the repeat rows for one employer represent repeated violations for different issues\n",
    "\n",
    "There are various ways to check duplicates in this data (eg converting `Violation` to lowercase; replacing spelled-out states with two-dig state codes)\n",
    "\n",
    "We're going to use the simple rule of:\n",
    "\n",
    "- A row is a duplicate if, within an employer (defined by Name + City, State), the Start date for each row's violation is the same \n",
    "\n",
    "To begin to check this, reshape `mult_debar` to a wide dataframe (`mult_debar_wide`) with the following columns, treating the `Name` and `City, State` as the index for the pivot:\n",
    "\n",
    "- Name\n",
    "- City, State\n",
    "- start_date_viol1\n",
    "- start_date_viol2\n",
    "\n",
    "Print the head and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6        5/9/2014\n",
      "7        7/6/2014\n",
      "8       7/20/2014\n",
      "11      8/20/2014\n",
      "12      8/23/2014\n",
      "14     11/16/2014\n",
      "15     11/16/2014\n",
      "16     11/16/2014\n",
      "17     11/16/2014\n",
      "18     12/10/2014\n",
      "19     12/10/2014\n",
      "21     12/11/2014\n",
      "24      8/23/2014\n",
      "25      8/20/2014\n",
      "28      7/20/2014\n",
      "29       7/6/2014\n",
      "30       5/9/2014\n",
      "31      2/13/2015\n",
      "51     12/11/2014\n",
      "55      2/13/2015\n",
      "56     12/10/2014\n",
      "58     12/10/2014\n",
      "59     11/16/2014\n",
      "60     11/16/2014\n",
      "61     11/16/2014\n",
      "62     11/16/2014\n",
      "73      6/16/2016\n",
      "89      6/16/2016\n",
      "103      2/9/2018\n",
      "106       7/17/19\n",
      "109      2/9/2018\n",
      "111       7/17/19\n",
      "Name: start_date_viol1, dtype: object\n",
      "6        5/9/2014\n",
      "7        7/6/2014\n",
      "8       7/20/2014\n",
      "11      8/20/2014\n",
      "12      8/23/2014\n",
      "14     11/16/2014\n",
      "15     11/16/2014\n",
      "16     11/16/2014\n",
      "17     11/16/2014\n",
      "18     12/10/2014\n",
      "19     12/10/2015\n",
      "21      12/1/2014\n",
      "24      8/23/2014\n",
      "25      8/20/2014\n",
      "28      7/20/2014\n",
      "29       7/6/2014\n",
      "30       5/9/2014\n",
      "31      2/13/2015\n",
      "51      12/1/2014\n",
      "55      2/13/2015\n",
      "56     12/10/2015\n",
      "58     12/10/2014\n",
      "59     11/16/2014\n",
      "60     11/16/2014\n",
      "61     11/16/2014\n",
      "62     11/16/2014\n",
      "73      9/27/2017\n",
      "89      9/27/2017\n",
      "103      2/9/2018\n",
      "106       7/17/19\n",
      "109      2/9/2018\n",
      "111       7/17/19\n",
      "Name: start_date_viol2, dtype: object\n",
      "Head of mult_debar_wide:\n",
      "                                       Name       City, State  \\\n",
      "0                   Annabella Land & Cattle     Annabella, UT   \n",
      "1                       Autumn Hill Orchard        Groton, MA   \n",
      "2     Caddo Creek Ranch, dba Paradise Ranch         Caddo, TX   \n",
      "3                        Cisco Produce Inc.         Cairo, GA   \n",
      "4                          Dove Creek Farms  Mount Vernon, TX   \n",
      "5                                 F&W Farms       Ingalls, KS   \n",
      "6                     Loewen Harvesting LLC   Brownsville, TX   \n",
      "7                      Macky and Brad Farms        Plains, TX   \n",
      "8          Maple Ridge Custom Services, LLC     Altheimer, AR   \n",
      "9                               Mark Duncan     Roosevelt, UT   \n",
      "10  Old Tree Farms/Verpaalen Custom Service         Volga, SD   \n",
      "11              Rollo Farm Labor Contractor         Miami, FL   \n",
      "12                                SRT Farms        Morton, TX   \n",
      "13                            Sharon Mathis        Tifton, GA   \n",
      "14                             Turner Farms         Healy, KS   \n",
      "15                             Xavier Horne    Lyons, Georgia   \n",
      "\n",
      "   start_date_viol1 start_date_viol2  \n",
      "0          5/9/2014         5/9/2014  \n",
      "1          7/6/2014         7/6/2014  \n",
      "2         7/20/2014        7/20/2014  \n",
      "3        12/10/2014       12/10/2015  \n",
      "4          2/9/2018         2/9/2018  \n",
      "5        12/10/2014       12/10/2014  \n",
      "6         8/20/2014        8/20/2014  \n",
      "7         2/13/2015        2/13/2015  \n",
      "8        11/16/2014       11/16/2014  \n",
      "9        11/16/2014       11/16/2014  \n",
      "10       12/11/2014        12/1/2014  \n",
      "11        8/23/2014        8/23/2014  \n",
      "12       11/16/2014       11/16/2014  \n",
      "13       11/16/2014       11/16/2014  \n",
      "14          7/17/19          7/17/19  \n",
      "15        6/16/2016        9/27/2017  \n",
      "\n",
      "Shape of mult_debar_wide: (16, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/t13xr4514214419m1ty47v1r0000gn/T/ipykernel_45156/2404006746.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mult_debar['City, State'] = mult_debar['City, State'].apply(clean_city_state)\n",
      "/var/folders/_f/t13xr4514214419m1ty47v1r0000gn/T/ipykernel_45156/2404006746.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mult_debar['Start date 2'] = stardate2\n",
      "/var/folders/_f/t13xr4514214419m1ty47v1r0000gn/T/ipykernel_45156/2404006746.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mult_debar['start_date_viol1'] = mult_debar.groupby(['Name', 'City, State'])['Start date'].transform('first')\n",
      "/var/folders/_f/t13xr4514214419m1ty47v1r0000gn/T/ipykernel_45156/2404006746.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mult_debar['start_date_viol2'] = mult_debar.groupby(['Name', 'City, State'])['Start date 2'].transform('last')\n"
     ]
    }
   ],
   "source": [
    "state_map = {'Texas': 'TX', \"Brownfield\": \"Brownsville\", \"AK\": \"AR\", \"Utah\": \"UT\"}\n",
    "\n",
    "def clean_city_state(city_state):\n",
    "    for keyword, replacement in state_map.items():\n",
    "        if keyword in city_state:\n",
    "            return city_state.replace(keyword, replacement)\n",
    "    return city_state\n",
    "\n",
    "mult_debar['City, State'] = mult_debar['City, State'].apply(clean_city_state)\n",
    "\n",
    "\n",
    "for name in mult_debar['Name']:\n",
    "    for name2 in mult_debar['Name']:\n",
    "        if name == name2:\n",
    "            stardate2 =  mult_debar['Start date']\n",
    "            mult_debar['Start date 2'] = stardate2\n",
    "\n",
    "\n",
    "mult_debar['start_date_viol1'] = mult_debar.groupby(['Name', 'City, State'])['Start date'].transform('first')\n",
    "print(mult_debar['start_date_viol1'])\n",
    "\n",
    "mult_debar['start_date_viol2'] = mult_debar.groupby(['Name', 'City, State'])['Start date 2'].transform('last')\n",
    "print(mult_debar['start_date_viol2'])\n",
    "\n",
    "\n",
    "mult_debar_wide = mult_debar.pivot_table(index=['Name', 'City, State'],\n",
    "                                         columns=None,\n",
    "                                         values=[\"start_date_viol1\", \"start_date_viol2\"],\n",
    "                                         aggfunc='first')\n",
    "\n",
    "mult_debar_wide.reset_index(inplace=True)\n",
    "\n",
    "print(\"Head of mult_debar_wide:\")\n",
    "print(mult_debar_wide)\n",
    "print(\"\\nShape of mult_debar_wide:\", mult_debar_wide.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Filter out duplicates from original debar data (6 points)\n",
    "\n",
    "A. Using `mult_debar_wide`, add a column `is_dup` that takes value of True for cases where start_date_viol1 == start_date_viol2 marking the row as a duplicate\n",
    "\n",
    "B. Going back to the original long-format data you loaded at the beginning- `debar`\n",
    "    - For employers where `is_dup == True` as indicated by your wide-format dataframe, only keep `violnum == viol1`\n",
    "    - For all other employers (so is_dup == False and ones we didnt need to check duplicates for), keep all violnum\n",
    "    - Remove the `is_repeated` column from the `debar` data\n",
    "\n",
    "**Hint**: you can complete part B without a for loop; `pd.concat` with axis = 0 (row binding) is one way\n",
    "\n",
    "Call the resulting dataframe `debar_clean` and print the shape and # of unique employer names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 9)\n",
      "98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/t13xr4514214419m1ty47v1r0000gn/T/ipykernel_45156/1701633796.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_duplicates.drop(columns='is_repeated', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## your code here\n",
    "mult_debar_wide[\"is_dup\"] = (mult_debar_wide[\"start_date_viol1\"] == mult_debar_wide[\"start_date_viol2\"])\n",
    "\n",
    "\n",
    "duplicates = mult_debar_wide[mult_debar_wide['is_dup']]\n",
    "duplicates.shape\n",
    "\n",
    "non_duplicates = debar[~debar['Name'].isin(duplicates['Name'])]\n",
    "\n",
    "non_duplicates.drop(columns='is_repeated', inplace=True)\n",
    "\n",
    "debar_clean = pd.concat([duplicates, non_duplicates], axis=0)\n",
    "\n",
    "print(debar_clean.shape)\n",
    "print(debar_clean[\"Name\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Merging and regex (17 points total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load data on job postings\n",
    "\n",
    "The previous dataset contains a small subset of employers who faced temporary bans due to violations of H-2A program regulations\n",
    "\n",
    "Since most of the bans have expired, we're going to see which of those employers posted new H-2A jobs in the first quarter of 2021 \n",
    "\n",
    "Loading the `jobs_clean.csv` data stored in `pset4_inputdata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              CASE_NUMBER                           CASE_STATUS  \\\n",
      "0     H-300-20199-721302      Determination Issued - Withdrawn   \n",
      "1     H-300-20231-773906  Determination Issued - Certification   \n",
      "2     H-300-20231-774123  Determination Issued - Certification   \n",
      "3     H-300-20231-774151  Determination Issued - Certification   \n",
      "4     H-300-20231-774508  Determination Issued - Certification   \n",
      "...                  ...                                   ...   \n",
      "2715  H-300-20351-963307  Determination Issued - Certification   \n",
      "2716  H-300-20351-963399  Determination Issued - Certification   \n",
      "2717  H-300-20351-964097  Determination Issued - Certification   \n",
      "2718  H-300-20351-965435  Determination Issued - Certification   \n",
      "2719  H-300-20352-967311  Determination Issued - Certification   \n",
      "\n",
      "                RECEIVED_DATE            DECISION_DATE  \\\n",
      "0     2020-07-17 14:50:40.840  2020-10-01 00:00:00.000   \n",
      "1     2020-08-20 10:38:15.620  2020-10-01 00:00:00.000   \n",
      "2     2020-08-24 15:33:14.340  2020-10-01 00:00:00.000   \n",
      "3     2020-08-21 12:08:09.760  2020-10-01 00:00:00.000   \n",
      "4     2020-08-20 10:17:34.530  2020-10-01 00:00:00.000   \n",
      "...                       ...                      ...   \n",
      "2715  2020-12-17 10:34:09.530  2020-12-31 00:00:00.000   \n",
      "2716  2020-12-17 14:37:57.920  2020-12-31 00:00:00.000   \n",
      "2717  2020-12-22 12:21:32.370  2020-12-31 00:00:00.000   \n",
      "2718  2020-12-22 12:18:43.280  2020-12-31 00:00:00.000   \n",
      "2719  2020-12-22 11:10:37.480  2020-12-31 00:00:00.000   \n",
      "\n",
      "     TYPE_OF_EMPLOYER_APPLICATION H2A_LABOR_CONTRACTOR  \\\n",
      "0             Individual Employer                    N   \n",
      "1             Association - Agent                    N   \n",
      "2             Individual Employer                    N   \n",
      "3             Individual Employer                    N   \n",
      "4             Individual Employer                    Y   \n",
      "...                           ...                  ...   \n",
      "2715          Individual Employer                    N   \n",
      "2716          Individual Employer                    N   \n",
      "2717          Individual Employer                    N   \n",
      "2718          Individual Employer                    N   \n",
      "2719          Individual Employer                    N   \n",
      "\n",
      "     NATURE_OF_TEMPORARY_NEED EMERGENCY_FILING  \\\n",
      "0                    Seasonal                Y   \n",
      "1                    Seasonal                N   \n",
      "2                    Seasonal                N   \n",
      "3                    Seasonal                N   \n",
      "4                    Seasonal                N   \n",
      "...                       ...              ...   \n",
      "2715                 Seasonal                N   \n",
      "2716                 Seasonal                N   \n",
      "2717                 Seasonal                N   \n",
      "2718                 Seasonal                N   \n",
      "2719                 Seasonal                N   \n",
      "\n",
      "                           EMPLOYER_NAME               TRADE_NAME_DBA  ...  \\\n",
      "0     Fazio Farms Operating Company, LLC                          NaN  ...   \n",
      "1                     Charlie Sunderland  Panter & Sunderland Nursery  ...   \n",
      "2                      Michael Rudebusch                          NaN  ...   \n",
      "3                           Lodahl Farms                          NaN  ...   \n",
      "4                Dunson Harvesting, Inc.      Dunson Harvesting, Inc.  ...   \n",
      "...                                  ...                          ...  ...   \n",
      "2715                   James L Schneller                          NaN  ...   \n",
      "2716                     Stephen G Myers                          NaN  ...   \n",
      "2717                          Andy Povey             Andy Povey Farms  ...   \n",
      "2718              Silver Creek Seed, LLC                          NaN  ...   \n",
      "2719                      Halabura Farms                          NaN  ...   \n",
      "\n",
      "     ADDENDUM_B_HOUSING_ATTACHED TOTAL_HOUSING_RECORDS MEALS_PROVIDED  \\\n",
      "0                              N                     1              Y   \n",
      "1                              N                     1              N   \n",
      "2                              N                     1              N   \n",
      "3                              Y                     2              N   \n",
      "4                              Y                     8              N   \n",
      "...                          ...                   ...            ...   \n",
      "2715                           N                     1              N   \n",
      "2716                           N                     1              N   \n",
      "2717                           Y                     2              Y   \n",
      "2718                           Y                     2              Y   \n",
      "2719                           N                     1              Y   \n",
      "\n",
      "     MEALS_CHARGED MEAL_REIMBURSEMENT_MINIMUM MEAL_REIMBURSEMENT_MAXIMUM  \\\n",
      "0            12.68                      12.68                       55.0   \n",
      "1              NaN                      12.68                       55.0   \n",
      "2              NaN                      12.68                       55.0   \n",
      "3              NaN                      12.68                       55.0   \n",
      "4              NaN                      12.68                       55.0   \n",
      "...            ...                        ...                        ...   \n",
      "2715           NaN                      12.68                       55.0   \n",
      "2716           NaN                      12.68                       55.0   \n",
      "2717         12.68                      12.68                       55.0   \n",
      "2718         12.68                      12.68                       55.0   \n",
      "2719         12.68                      12.68                       55.0   \n",
      "\n",
      "     PHONE_TO_APPLY                  EMAIL_TO_APPLY  \\\n",
      "0       13607017661            faziofarms@gmail.com   \n",
      "1       19318083783                             NaN   \n",
      "2       19369333827   fayethlynpitre@rocketmail.com   \n",
      "3       14069637560         lodahl_kelsey@yahoo.com   \n",
      "4       18632939888                             NaN   \n",
      "...             ...                             ...   \n",
      "2715    12709914373                jims4463@aol.com   \n",
      "2716    12708780028                vjpm76@gmail.com   \n",
      "2717            NaN  H-2AJobs@snakeriverfarmers.org   \n",
      "2718            NaN  H-2AJobs@snakeriverfarmers.org   \n",
      "2719            NaN          referrals@maslabor.com   \n",
      "\n",
      "                                       WEBSITE_TO_APPLY  \\\n",
      "0                                                   NaN   \n",
      "1           https://www.jobs4tn.gov/vosnet/Default.aspx   \n",
      "2                                                   NaN   \n",
      "3                                                   NaN   \n",
      "4                                 www.employflorida.com   \n",
      "...                                                 ...   \n",
      "2715                                                NaN   \n",
      "2716  https://kentucky.gov/employment/Pages/default....   \n",
      "2717            https://idahoworks.gov/ada/r/job_seeker   \n",
      "2718            https://idahoworks.gov/ada/r/job_seeker   \n",
      "2719                    https://www.pacareerlink.pa.gov   \n",
      "\n",
      "      TOTAL_ADDENDUM_A_RECORDS  \n",
      "0                            0  \n",
      "1                            0  \n",
      "2                            0  \n",
      "3                            0  \n",
      "4                            4  \n",
      "...                        ...  \n",
      "2715                         0  \n",
      "2716                         1  \n",
      "2717                         0  \n",
      "2718                         0  \n",
      "2719                         0  \n",
      "\n",
      "[2720 rows x 138 columns]>\n"
     ]
    }
   ],
   "source": [
    "# your code here to load the data \n",
    "\n",
    "jobs = pd.read_csv(r\"/Users/fintanletzelter/Documents/GitHub/QSS20_S24/problemsets/pset2/pset2_inputdata/jobs.csv\")\n",
    "print(jobs.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.2 Try inner join on employer name  (2 points)\n",
    "\n",
    "- Use the `EMPLOYER_NAME` field of the `jobs` dataset\n",
    "- Use the `Name` field of the `debar_clean` dataset \n",
    "\n",
    "A. Use pd.merge with an inner join on those fields to see whether there are any exact matches. \n",
    "\n",
    "B. If there are exact matches, print the row(s) with exact matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CASE_NUMBER                           CASE_STATUS  \\\n",
      "0  H-300-20287-876656  Determination Issued - Certification   \n",
      "\n",
      "             RECEIVED_DATE            DECISION_DATE  \\\n",
      "0  2020-10-20 09:20:32.010  2020-11-09 00:00:00.000   \n",
      "\n",
      "  TYPE_OF_EMPLOYER_APPLICATION H2A_LABOR_CONTRACTOR NATURE_OF_TEMPORARY_NEED  \\\n",
      "0          Individual Employer                    Y                 Seasonal   \n",
      "\n",
      "  EMERGENCY_FILING   EMPLOYER_NAME TRADE_NAME_DBA  ...  \\\n",
      "0                Y  Rafael Barajas            NaN  ...   \n",
      "\n",
      "  TOTAL_ADDENDUM_A_RECORDS            Name       City, State start_date_viol1  \\\n",
      "0                        7  Rafael Barajas  Sebring, Florida              NaN   \n",
      "\n",
      "  start_date_viol2 is_dup                         Violation  Duration  \\\n",
      "0              NaN    NaN  Non-payment of certification fee    1 year   \n",
      "\n",
      "   Start date   End date  \n",
      "0   9/23/2016  9/22/2017  \n",
      "\n",
      "[1 rows x 147 columns]\n"
     ]
    }
   ],
   "source": [
    "## your code here\n",
    "\n",
    "jobs_debar = jobs.merge(debar_clean, left_on = \"EMPLOYER_NAME\", right_on = \"Name\", how = \"inner\")\n",
    "print(jobs_debar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Targeted regex (10 points total)\n",
    "\n",
    "You want to see if you can increase the exact match rate with some basic cleaning of each \n",
    "of the employer name fields in each dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Converting to upper (2 points)\n",
    "\n",
    "A. Convert the `EMPLOYER_NAME` and `Name` fields to uppercase using list comprehension rather than df.varname.str.upper() (it's fine to do a separate list comprehension line for each of the two columns)\n",
    "\n",
    "B. Print a random sample of 15 values of each result\n",
    "\n",
    "C. Assign the full vector of uppercase names back to the original data, writing over the original `EMPLOYER_NAME` and `Name` columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code to turn into uppercase here\n",
    "\n",
    "jobs_names = [str.upper(name) for name in jobs[\"EMPLOYER_NAME\"]]\n",
    "\n",
    "debar_names = [str.upper(name) for name in debar_clean[\"Name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1634                   DR Livestock\n",
      "2610            Sharon J Stamatakis\n",
      "1694       N & L Johnson Farms, LLC\n",
      "2220              Mathias A. Miller\n",
      "1360    Johnsons Mountain Ranch LLC\n",
      "865         Carlson Harvesting Inc.\n",
      "979                    Damon Weigel\n",
      "638                    Stephen Towe\n",
      "260                  La Alianza, LP\n",
      "2212     Kunzler Sheep & Cattle Co.\n",
      "1487       Flowerwood Nursery, Inc.\n",
      "994                    Alex Hollman\n",
      "2341          Galen Scheresky Farms\n",
      "713        JG Labor Harvesting, LLC\n",
      "1373                M & M Farms LLC\n",
      "Name: EMPLOYER_NAME, dtype: object\n",
      "27                          Yolanda Chavez Farming\n",
      "87                               Leslie Renee Drew\n",
      "7                             Macky and Brad Farms\n",
      "64                              Gonzalo Fernandez*\n",
      "100                              Evergreen Produce\n",
      "82                                   Labatte Farms\n",
      "5                                        F&W Farms\n",
      "39                            Valley View Orchards\n",
      "38                                     Leslie Cook\n",
      "4                 Great Plains Fluid Service, Inc.\n",
      "52                               Louie M. Asumendi\n",
      "84                            Landmark Landscaping\n",
      "1                              Autumn Hill Orchard\n",
      "105                                    J & L Farms\n",
      "112    B & R Harvesting and Paul Cruz (individual)\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## insert your code for the random sample\n",
    "print(jobs[\"EMPLOYER_NAME\"].sample(n = 15))\n",
    "print(debar_clean[\"Name\"].sample(n = 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code for assigning the uppercase names back to the data\n",
    "jobs[\"EMPLOYER_NAME\"] = jobs_names\n",
    "debar_clean[\"Name\"] = debar_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Cleaning up punctuation (4 points)\n",
    "\n",
    "You notice that INC, CO, and LLC are sometimes followed by a period (.) but sometimes not\n",
    "\n",
    "A. For each dataset, write a regex pattern using `re.sub` to remove the . but only if it's preceded by INC, LLC, or CO \n",
    "\n",
    "Make sure LLC, INC, CO remain part of the string but just without the dot\n",
    "\n",
    "B. Test the pattern on the positive and negative example we provide below and print the result. See the Github issue for examples of what to return\n",
    "\n",
    "\n",
    "**Hint**: https://stackoverflow.com/questions/7191209/python-re-sub-replace-with-matched-content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_example_1 = \"CISCO PRODUCE INC.\"\n",
    "pos_example_2 = \"AVOYELLES HONEY CO., LLC\"\n",
    "neg_example = \"E.V. RANCH LLP\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(13, 18), match=' INC.'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(15, 19), match=' CO.'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## insert your code here with the regex pattern for part A\n",
    "\n",
    "pattern1 = r\"(\\s+)(INC|CO|LLC)(\\.)?\"\n",
    "\n",
    "## insert your code to use re.sub to apply the pattern to the test cases for part B\n",
    "\n",
    "\n",
    "re.search(pattern1, pos_example_1)\n",
    "re.search(pattern1, pos_example_2)\n",
    "re.search(pattern1, neg_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 (4 points)\n",
    "\n",
    "Use that pattern in conjunction with `re.sub` and list comprehension to clean the employer name columns in each dataset. Save the new columns as `name_clean` in each. Then, use row subsetting to (1) subset to rows that changed names and (2) for:\n",
    "\n",
    "- `debar_clean` print the `Name` and `name_clean` columns\n",
    "- `jobs` print the `EMPLOYER_NAME` and `name_clean` columns\n",
    "\n",
    "Make sure to use the uppercase versions of the variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to clean the columns\n",
    "\n",
    "debar_clean[\"name_clean\"] = [re.sub(pattern1, r\"\\1\\2\", name) for name in debar_clean[\"Name\"]]\n",
    "jobs[\"name_clean\"] = [re.sub(pattern1, r\"\\1\\2\", name) for name in jobs[\"EMPLOYER_NAME\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           CASE_NUMBER                                     CASE_STATUS  \\\n",
      "4   H-300-20231-774508            Determination Issued - Certification   \n",
      "7   H-300-20233-780540  Determination Issued - Certification (Expired)   \n",
      "14  H-300-20240-791807  Determination Issued - Certification (Expired)   \n",
      "17  H-300-20244-795767            Determination Issued - Certification   \n",
      "18  H-300-20245-799651            Determination Issued - Certification   \n",
      "\n",
      "              RECEIVED_DATE            DECISION_DATE  \\\n",
      "4   2020-08-20 10:17:34.530  2020-10-01 00:00:00.000   \n",
      "7   2020-09-04 14:26:00.270  2020-10-01 00:00:00.000   \n",
      "14  2020-09-17 18:57:56.030  2020-10-01 00:00:00.000   \n",
      "17  2020-09-16 12:58:58.600  2020-10-01 00:00:00.000   \n",
      "18  2020-09-02 11:17:48.730  2020-10-01 00:00:00.000   \n",
      "\n",
      "    TYPE_OF_EMPLOYER_APPLICATION H2A_LABOR_CONTRACTOR  \\\n",
      "4            Individual Employer                    Y   \n",
      "7   Association - Joint Employer                    N   \n",
      "14           Individual Employer                    N   \n",
      "17           Individual Employer                    N   \n",
      "18           Individual Employer                    N   \n",
      "\n",
      "   NATURE_OF_TEMPORARY_NEED EMERGENCY_FILING  \\\n",
      "4                  Seasonal                N   \n",
      "7                  Seasonal                N   \n",
      "14                 Seasonal                N   \n",
      "17                 Seasonal                N   \n",
      "18                 Seasonal                N   \n",
      "\n",
      "                               EMPLOYER_NAME           TRADE_NAME_DBA  ...  \\\n",
      "4                    DUNSON HARVESTING, INC.  Dunson Harvesting, Inc.  ...   \n",
      "7   FARM LABOR ASSOCIATION FOR GROWERS, INC.                      NaN  ...   \n",
      "14                        MCLAIN FARMS, INC.                      NaN  ...   \n",
      "17                       BONNIE PLANTS, INC.                      NaN  ...   \n",
      "18               B & W QUALITY GROWERS, INC.                      NaN  ...   \n",
      "\n",
      "   TOTAL_HOUSING_RECORDS MEALS_PROVIDED MEALS_CHARGED  \\\n",
      "4                      8              N           NaN   \n",
      "7                      1              Y          13.5   \n",
      "14                     1              N           NaN   \n",
      "17                     1              N           NaN   \n",
      "18                    33              N           NaN   \n",
      "\n",
      "   MEAL_REIMBURSEMENT_MINIMUM MEAL_REIMBURSEMENT_MAXIMUM PHONE_TO_APPLY  \\\n",
      "4                       12.68                       55.0    18632939888   \n",
      "7                       13.50                       55.0    17605922256   \n",
      "14                      12.68                       55.0    19125268436   \n",
      "17                      12.68                       55.0    13343911328   \n",
      "18                      12.68                       55.0    17725711135   \n",
      "\n",
      "                   EMAIL_TO_APPLY       WEBSITE_TO_APPLY  \\\n",
      "4                             NaN  www.employflorida.com   \n",
      "7                  flag@sfcos.com                    NaN   \n",
      "14            kim@mclainfarms.com                    NaN   \n",
      "17  dennis.ucles@bonnieplants.com                    NaN   \n",
      "18                            NaN  www.employflorida.com   \n",
      "\n",
      "    TOTAL_ADDENDUM_A_RECORDS                               name_clean  \n",
      "4                          4                   DUNSON HARVESTING, INC  \n",
      "7                          9  FARM LABOR ASSOCIATION FOR GROWERS, INC  \n",
      "14                         1                        MCLAIN FARMS, INC  \n",
      "17                         0                       BONNIE PLANTS, INC  \n",
      "18                         7               B & W QUALITY GROWERS, INC  \n",
      "\n",
      "[5 rows x 139 columns]\n",
      "                                Name     City, State start_date_viol1  \\\n",
      "3              ANTON FERTILIZER INC.     Dighton, KS              NaN   \n",
      "4   GREAT PLAINS FLUID SERVICE, INC.  Greensburg, KS              NaN   \n",
      "5                        PROMAX INC.  Whitewater, KS              NaN   \n",
      "13                     REIMER'S INC.       Lakin, KS              NaN   \n",
      "19                CISCO PRODUCE INC.       Cairo, GA              NaN   \n",
      "\n",
      "   start_date_viol2 is_dup                                  Violation  \\\n",
      "3               NaN    NaN  Failure to respond to audit (no response)   \n",
      "4               NaN    NaN  Failure to respond to audit (no response)   \n",
      "5               NaN    NaN               Failure to Hire U.S. workers   \n",
      "13              NaN    NaN  Failure to respond to audit (no response)   \n",
      "19              NaN    NaN  Failure to respond to audit (no response)   \n",
      "\n",
      "   Duration  Start date   End date                       name_clean  \n",
      "3   2 years   3/30/2014  3/29/2016             ANTON FERTILIZER INC  \n",
      "4   2 years   3/30/2014  3/29/2016  GREAT PLAINS FLUID SERVICE, INC  \n",
      "5   2 years   5/15/2014  5/14/2016                       PROMAX INC  \n",
      "13  2 years   8/23/2014  8/22/2016                     REIMER'S INC  \n",
      "19  2 years  12/10/2014  12/9/2016                CISCO PRODUCE INC  \n"
     ]
    }
   ],
   "source": [
    "## your code here to print the head\n",
    "print(jobs[jobs[\"EMPLOYER_NAME\"] != jobs[\"name_clean\"]].head())\n",
    "print(debar_clean[debar_clean[\"Name\"] != debar_clean[\"name_clean\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 More joins and more cleaning (5 points)\n",
    "\n",
    "A. Conduct another inner join between `jobs` and `debar_clean` now using the `name_clean` column; print the result. Did the cleaning result in any more employers matched between the two datasets?\n",
    "\n",
    "B. Create a new column in `debar_clean` called `name_clean_2` that uses regex to take the following name in that dataset:\n",
    "\n",
    "- `SLASH E.V. RANCH LLP` in the `debar_clean` dataset\n",
    "\n",
    "And cleans it up so that it matches with this employer in `jobs`\n",
    "\n",
    "- `SLASH EV RANCH` in the `jobs` dataset\n",
    "\n",
    "Eg a pattern to remove the dots in the EV and the space+LLP-- you can apply the pattern to all employer names in debar_clean (so don't need to worry about only applying it to that one employer)\n",
    "\n",
    "\n",
    "C. Conduct a left join using `name_clean_2` as the join column where the left hand dataframe is `jobs`; right hand dataframe is `debar_clean`, store the result as a dataframe, and print the rows where the merge indicator indicates the row was found in both dataframe\n",
    "\n",
    "**Note**: this manual cleaning process is inefficient and helps motivate why talked about fuzzy matching. Fuzzy matching could recognize that Slash EV ranch is a highly similar string to slash ev ranch llp and match them without us needing to use regex to make the strings identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 149)\n",
      "             CASE_NUMBER                           CASE_STATUS  \\\n",
      "1115  H-300-20306-894148  Determination Issued - Certification   \n",
      "\n",
      "                RECEIVED_DATE            DECISION_DATE  \\\n",
      "1115  2020-11-02 18:11:29.140  2020-11-24 00:00:00.000   \n",
      "\n",
      "     TYPE_OF_EMPLOYER_APPLICATION H2A_LABOR_CONTRACTOR  \\\n",
      "1115          Individual Employer                    N   \n",
      "\n",
      "     NATURE_OF_TEMPORARY_NEED EMERGENCY_FILING   EMPLOYER_NAME TRADE_NAME_DBA  \\\n",
      "1115                 Seasonal                N  SLASH EV RANCH            NaN   \n",
      "\n",
      "      ... TOTAL_HOUSING_RECORDS MEALS_PROVIDED MEALS_CHARGED  \\\n",
      "1115  ...                     1              N           NaN   \n",
      "\n",
      "     MEAL_REIMBURSEMENT_MINIMUM MEAL_REIMBURSEMENT_MAXIMUM PHONE_TO_APPLY  \\\n",
      "1115                      12.68                       55.0    13034896355   \n",
      "\n",
      "             EMAIL_TO_APPLY            WEBSITE_TO_APPLY  \\\n",
      "1115  sallyloulou13@aol.com  www.connectingcolorado.com   \n",
      "\n",
      "      TOTAL_ADDENDUM_A_RECORDS      name_clean  \n",
      "1115                         0  SLASH EV RANCH  \n",
      "\n",
      "[1 rows x 139 columns]\n",
      "                    Name City, State start_date_viol1 start_date_viol2 is_dup  \\\n",
      "20  SLASH E.V. RANCH LLP   Rifle, CO              NaN              NaN    NaN   \n",
      "\n",
      "        Violation Duration  Start date    End date            name_clean  \\\n",
      "20  WHD Debarment   1 year  11/15/2014  11/14/2015  SLASH E.V. RANCH LLP   \n",
      "\n",
      "      name_clean_2  \n",
      "20  SLASH EV RANCH  \n",
      "             CASE_NUMBER                           CASE_STATUS  \\\n",
      "791   H-300-20287-876656  Determination Issued - Certification   \n",
      "1115  H-300-20306-894148  Determination Issued - Certification   \n",
      "\n",
      "                RECEIVED_DATE            DECISION_DATE  \\\n",
      "791   2020-10-20 09:20:32.010  2020-11-09 00:00:00.000   \n",
      "1115  2020-11-02 18:11:29.140  2020-11-24 00:00:00.000   \n",
      "\n",
      "     TYPE_OF_EMPLOYER_APPLICATION H2A_LABOR_CONTRACTOR  \\\n",
      "791           Individual Employer                    Y   \n",
      "1115          Individual Employer                    N   \n",
      "\n",
      "     NATURE_OF_TEMPORARY_NEED EMERGENCY_FILING   EMPLOYER_NAME TRADE_NAME_DBA  \\\n",
      "791                  Seasonal                Y  RAFAEL BARAJAS            NaN   \n",
      "1115                 Seasonal                N  SLASH EV RANCH            NaN   \n",
      "\n",
      "      ... start_date_viol1 start_date_viol2 is_dup  \\\n",
      "791   ...              NaN              NaN    NaN   \n",
      "1115  ...              NaN              NaN    NaN   \n",
      "\n",
      "                             Violation Duration  Start date    End date  \\\n",
      "791   Non-payment of certification fee   1 year   9/23/2016   9/22/2017   \n",
      "1115                     WHD Debarment   1 year  11/15/2014  11/14/2015   \n",
      "\n",
      "              name_clean_y    name_clean_2  was_match  \n",
      "791         RAFAEL BARAJAS  RAFAEL BARAJAS       both  \n",
      "1115  SLASH E.V. RANCH LLP  SLASH EV RANCH       both  \n",
      "\n",
      "[2 rows x 151 columns]\n"
     ]
    }
   ],
   "source": [
    "## your code here\n",
    "jobs_debar_clean = jobs.merge(debar_clean, on = \"name_clean\", how = \"inner\")\n",
    "print(jobs_debar_clean.shape)\n",
    "\n",
    "\n",
    "pattern2 = r\"(SLASH)\\s(E)\\.(V)\\.\\s(RANCH)\\s(LLP)\"\n",
    "\n",
    "debar_clean[\"name_clean_2\"] = [re.sub(pattern2, r\"\\1 \\2\\3 \\4\", name) for name in debar_clean[\"name_clean\"]]\n",
    "\n",
    "print(jobs[jobs[\"name_clean\"] == \"SLASH EV RANCH\"])\n",
    "print(debar_clean[debar_clean[\"name_clean_2\"] == \"SLASH EV RANCH\"])\n",
    "\n",
    "jobs_debar_left = jobs.merge(debar_clean, left_on = \"name_clean\", right_on = \"name_clean_2\", how = \"left\", indicator = \"was_match\")\n",
    "print(jobs_debar_left[jobs_debar_left.was_match == \"both\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Optional extra credit 1: regex to separate companies from individuals (1 point)\n",
    "\n",
    "You notice some employers in `debar_clean` have both the name of the company and the name of individual, e.g.:\n",
    "    \n",
    "COUNTY FAIR FARM (COMPANY) AND ANDREW WILLIAMSON (INDIVIDUAL)*\n",
    "\n",
    "Use the uppercase/cleaned `name_clean` in `debar_clean`\n",
    "\n",
    "A. Write a regex pattern that does the following:\n",
    "    - Captures the pattern that occurs before COMPANY if (COMPANY) is in string; so in example above, extracts COUNTY FAIR FARM \n",
    "    - Captures the pattern that occurs before INDIVIDUAL if (INDIVIDUAL) is also in string -- so in above, extracts ANDREW WILLIAMSON (so omit the \"and\")\n",
    "    \n",
    "B. Test the pattern on `pos_example` and `neg_example`-- make sure former returns a list (if using find.all) or match object (if using re.search) with the company name and individual name separated out; make sure latter returns empty\n",
    "    \n",
    "**Hints and resources**: for step A, you can either use re.search, re.match, or re.findall; don't worry about matching B&R Harvesting and Paul Cruz (Individual)\n",
    "\n",
    "- Same regex resources as above\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNTY FAIR FARM  ANDREW WILLIAMSON \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pos_example = \"COUNTY FAIR FARM (COMPANY) AND ANDREW WILLIAMSON (INDIVIDUAL)*\"\n",
    "neg_example = \"CISCO PRODUCE INC\"\n",
    "\n",
    "pattern3 = r\"(([A-Z]+\\s)*)(\\(COMPANY\\))\\s(AND)\\s(([A-Z]+\\s)*)\\(INDIVIDUAL\\).\"\n",
    "\n",
    "new_string = re.sub(pattern3, r\"\\1 \\5\", pos_example)\n",
    "neg_string = re.search(pattern3, neg_example)\n",
    "print(new_string)\n",
    "print(neg_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Iterate over the `name_clean` column in debar and use regex to create two new columns in `debar_clean`:\n",
    "   - `co_name`: A column for company (full `name_clean` string if no match; pattern before COMPANY if one extracted)\n",
    "   - `ind_name`: A column for individual (full `name_clean` string if no match; pattern before INDIVIDUAL if one extracted)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "co_names = []\n",
    "ind_names = []\n",
    "\n",
    "for name in debar_clean[\"name_clean\"]:\n",
    "    if re.match(pattern3, name):\n",
    "        co_names.append(re.sub(pattern3, r\"\\1\", name))\n",
    "        ind_names.append(re.sub(pattern3, r\"\\5\", name))\n",
    "    else:\n",
    "        co_names.append(None)\n",
    "        ind_names.append(None)\n",
    "\n",
    "\n",
    "debar_clean[\"co_name\"] = co_names\n",
    "debar_clean[\"ind_name\"] = ind_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "D. Print three columns for the rows in `debar_clean` containing the negative example and positive example described above (county fair farm and cisco produce):\n",
    "\n",
    "- `name_clean`\n",
    "- `co_name`\n",
    "- `ind_name`\n",
    "- `Violation`\n",
    "\n",
    "**Note**: as shown in the outcome there may be duplicates of the same company reflecting different violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            name_clean            co_name  \\\n",
      "19                                   CISCO PRODUCE INC               None   \n",
      "56                                   CISCO PRODUCE INC               None   \n",
      "108  COUNTY FAIR FARM (COMPANY) AND ANDREW WILLIAMS...  COUNTY FAIR FARM    \n",
      "\n",
      "               ind_name                                   Violation  \n",
      "19                 None   Failure to respond to audit (no response)  \n",
      "56                 None  Impeding the Audit Process – Non- Response  \n",
      "108  ANDREW WILLIAMSON                                WHD Debarment  \n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "print(debar_clean[debar_clean[\"name_clean\"].isin([pos_example, neg_example])][[\"name_clean\", \"co_name\", \"ind_name\", \"Violation\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Optional extra credit 2 (up to 3 points)\n",
    "\n",
    "- For 1 point extra credit, create a visualization with 1+ of the existing fields in either the raw `jobs` or `debar` data. We'll be showing cool visualizations in class so use your imagination! Options could include visualizing between-state or over-time variation\n",
    "\n",
    "- For 3 points extra credit instead, geocode the employer addresses in `jobs` and plot the addresses of jobs as points overlaid on top of a map of Georgia \n",
    "    - **Note**: this extra credit involves Googling since we have not yet covered spatial data. \n",
    "        - For discussion of how to geocode addresses -> lat/long, see: https://www.natasshaselvaraj.com/a-step-by-step-guide-on-geocoding-in-python/ \n",
    "        - For discussion of plotting lat/long dots against a map, see this discussion of geopandas: https://towardsdatascience.com/plotting-maps-with-geopandas-428c97295a73\n",
    "    - Relevant columns include `EMPLOYER_ADDRESS_1` \n",
    "    - The geocoding might have a long runtime so feel free to implement it in a separate .py script that you submit alongside your notebook and to just read in the geocoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "state_abbreviations = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "def extract_state(city_state):\n",
    "    if isinstance(city_state, str):\n",
    "        return city_state.split(', ')[-1]\n",
    "    else:\n",
    "        return \"Unknown\" \n",
    "\n",
    "debar['State'] = debar['City, State'].apply(extract_state)\n",
    "\n",
    "def clean_city_state(state):\n",
    "    for keyword, replacement in state_abbreviations.items():\n",
    "        if keyword in state:\n",
    "            return state.replace(keyword, replacement)\n",
    "    return state\n",
    "\n",
    "debar['State'] = debar['State'].apply(clean_city_state)\n",
    "\n",
    "state_violation_counts = debar['State'].value_counts()\n",
    "\n",
    "print(state_violation_counts)\n",
    "\n",
    "state_violation_counts.plot(kind='bar', color='skyblue', figsize=(10, 6))\n",
    "\n",
    "plt.title('Number of Violations Per State')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Number of Violations')\n",
    "plt.xticks(rotation=60) \n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7 (main, Dec 15 2023, 12:09:04) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
